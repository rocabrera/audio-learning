{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754724b6-af7d-4334-a988-b56d5c78a8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# libs para preparar customs datasets\n",
    "from data_processor.dataset import MLS, CommonVoice\n",
    "from data_processor.cleaner import CreateTidyDataset\n",
    "\n",
    "# libs para conectar o custom dataset com a pipeline\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Especifico de wav2vec\n",
    "from datasets import load_metric\n",
    "from transformers import (Wav2Vec2CTCTokenizer, \n",
    "                          Wav2Vec2FeatureExtractor, \n",
    "                          Wav2Vec2Processor, \n",
    "                          Wav2Vec2ForCTC,\n",
    "                          TrainingArguments,\n",
    "                          Trainer)\n",
    "\n",
    "from core.utils import DataCollatorCTCWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f233cd1-cfca-42f3-8d2d-3924acb872cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mls = MLS(data_train_dir = \"data/mls_portuguese/train\", \n",
    "          data_test_dir  = \"data/mls_portuguese/test\",\n",
    "          data_dev_dir   = \"data/mls_portuguese/dev\")\n",
    "\n",
    "cov = CommonVoice(main_path = \"data/common_voice/cv-corpus-7.0-2021-07-21/pt\")\n",
    "\n",
    "databases = [(cov, True), (mls,True)]\n",
    "tidy_dataset = CreateTidyDataset(databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85dc34-e3cc-490b-99f7-5d2d8420e1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tidy_dataset.converter_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5265e-f631-4023-89ff-62489abea407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, test_df = tidy_dataset.parse_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e4490-3b9f-41b3-b74c-34a682f793c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse our dataset\n",
    "regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\'\\“\\&\\«\\´\\»\\”\\ü]'\n",
    "vocab = set(re.sub(regex, ' ', train_df[\"text\"].str.cat(sep='').lower(), count=0, flags=0))\n",
    "vocab.update({\"[UNK]\",\"[PAD]\"})\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab)}\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcba929-f8de-4158-8551-262febdfbc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Wav2vecDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.max_size = len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.df.loc[idx,[\"file\", \"text\"]].to_dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_size\n",
    "\n",
    "    \n",
    "train_dataset = Wav2vecDataset(train_df)\n",
    "test_dataset = Wav2vecDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_df, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_df, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b474c-49c2-4807-9088-9adf62523f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", \n",
    "                                 unk_token=\"[UNK]\", \n",
    "                                 pad_token=\"[PAD]\", \n",
    "                                 word_delimiter_token=\"|\")\n",
    "\n",
    "\"\"\"\n",
    "É importante saber o sampling_rate do embedding onde os embeddings foram pré treinados.\n",
    "\"\"\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, \n",
    "                                             sampling_rate=16000, \n",
    "                                             padding_value=0.0, \n",
    "                                             do_normalize=True, \n",
    "                                             return_attention_mask=False)\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634565dd-6ae5-4c34-aa31-b17283ebb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48859c6-5a9b-4da5-bd39-522a2eaae722",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base\", \n",
    "                                       gradient_checkpointing=True, \n",
    "                                       ctc_loss_reduction=\"mean\", \n",
    "                                       pad_token_id=processor.tokenizer.pad_token_id,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c3fc5-96b3-4b8d-8401-0ee11f4be1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  # output_dir=\"/content/gdrive/MyDrive/wav2vec2-base-timit-demo\",\n",
    "  output_dir=\"./wav2vec2-base-timit-demo\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=8,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=30,\n",
    "  fp16=True,\n",
    "  save_steps=500,\n",
    "  eval_steps=500,\n",
    "  logging_steps=500,\n",
    "  learning_rate=1e-4,\n",
    "  weight_decay=0.005,\n",
    "  warmup_steps=1000,\n",
    "  save_total_limit=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25e3c6-8045-41ba-bdfc-9fa1e8068f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  data_collator=data_collator,\n",
    "                  args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset=test_dataset,\n",
    "                  tokenizer=processor.feature_extractor,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f13432-13d5-479c-a82a-31dbb10492f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b88420-e498-4999-b5c4-8bbf58006a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_playground",
   "language": "python",
   "name": "venv_playground"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
